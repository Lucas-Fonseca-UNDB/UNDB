{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3763,"status":"ok","timestamp":1717004773965,"user":{"displayName":"Lucas Gabriel Sousa da Fonseca","userId":"13582328743319674228"},"user_tz":180},"id":"Yjc9tzGy13Cq"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6965,"status":"ok","timestamp":1717004784913,"user":{"displayName":"Lucas Gabriel Sousa da Fonseca","userId":"13582328743319674228"},"user_tz":180},"id":"COpwF9DQ13rI","outputId":"a895540f-b249-40b9-c0b2-e7950de57ad2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1202 images belonging to 2 classes.\n","Found 375 images belonging to 2 classes.\n"]}],"source":["# # Defina as classes\n","classes = ['apple', 'banana']\n","\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    'UNDB\\Cadeira-de-IA\\PBL2-Aplicações de Visão Computacional na Rede Mateus\\Dataset\\Training',  \n","    target_size=(64, 64),\n","    batch_size=32,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","# Crie um novo ImageDataGenerator para o conjunto de validação\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Gere os dados de validação\n","validation_generator = val_datagen.flow_from_directory(\n","    'UNDB\\Cadeira-de-IA\\PBL2-Aplicações de Visão Computacional na Rede Mateus\\Dataset\\Validation',  \n","    target_size=(64, 64),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","# Calcule o número de etapas de validação\n","num_validation_samples = len(validation_generator.filenames)\n","validation_steps = num_validation_samples // validation_generator.batch_size"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3246,"status":"ok","timestamp":1717004818943,"user":{"displayName":"Lucas Gabriel Sousa da Fonseca","userId":"13582328743319674228"},"user_tz":180},"id":"9DqKEnoAdMyt","outputId":"406393d9-6dc0-4275-be80-9c1431bfe499"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n"]}],"source":["# Carregar a arquitetura MobileNetV2\n","base_model = MobileNetV2(weights='imagenet', include_top=False)\n","\n","# Adicionar uma camada de GlobalAveragePooling2D\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","\n","# Adicionar uma camada densa com o número de classes como unidades e ativação softmax\n","predictions = Dense(len(classes), activation='softmax')(x)\n","\n","# Criar o modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428950,"status":"ok","timestamp":1717005256782,"user":{"displayName":"Lucas Gabriel Sousa da Fonseca","userId":"13582328743319674228"},"user_tz":180},"id":"66fvL775dGZc","outputId":"624f0de1-365d-49e9-9edd-1c4d97d4dd9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","38/38 [==============================] - 319s 8s/step - loss: 0.1038 - accuracy: 0.9617 - val_loss: 14.4476 - val_accuracy: 0.6932\n","Epoch 2/10\n","38/38 [==============================] - 7s 195ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 10.2857 - val_accuracy: 0.7898\n","Epoch 3/10\n","38/38 [==============================] - 5s 141ms/step - loss: 4.7488e-04 - accuracy: 1.0000 - val_loss: 8.4304 - val_accuracy: 0.8324\n","Epoch 4/10\n","38/38 [==============================] - 6s 150ms/step - loss: 8.9233e-05 - accuracy: 1.0000 - val_loss: 7.0357 - val_accuracy: 0.8352\n","Epoch 5/10\n","38/38 [==============================] - 6s 164ms/step - loss: 2.6882e-04 - accuracy: 1.0000 - val_loss: 5.0992 - val_accuracy: 0.8608\n","Epoch 6/10\n","38/38 [==============================] - 5s 142ms/step - loss: 2.5118e-04 - accuracy: 1.0000 - val_loss: 5.1170 - val_accuracy: 0.8551\n","Epoch 7/10\n","38/38 [==============================] - 6s 147ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 3.1148 - val_accuracy: 0.9006\n","Epoch 8/10\n","38/38 [==============================] - 7s 183ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.9290\n","Epoch 9/10\n","38/38 [==============================] - 6s 148ms/step - loss: 9.4361e-05 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9545\n","Epoch 10/10\n","38/38 [==============================] - 7s 172ms/step - loss: 1.3544e-04 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9773\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7cc2e02b1840>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Compilar o modelo\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","# Treinar o modelo\n","model.fit(train_generator,\n","          validation_data=validation_generator,\n","          steps_per_epoch=len(train_generator),\n","          validation_steps=validation_steps,\n","          epochs=10)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":759,"status":"ok","timestamp":1717005420956,"user":{"displayName":"Lucas Gabriel Sousa da Fonseca","userId":"13582328743319674228"},"user_tz":180},"id":"NDhYYJuoejoA","outputId":"e0921ad2-6671-48b6-f941-5b03f8b4ebe0"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 21ms/step\n","A imagem foi classificada como 'apple'.\n"]}],"source":["# Carregar a imagem\n","img_path = 'UNDB\\Cadeira-de-IA\\PBL2-Aplicações de Visão Computacional na Rede Mateus\\Dataset\\Test\\teste-21.jpg'\n","img = image.load_img(img_path, target_size=(64, 64))\n","\n","# Converter a imagem para um array numpy e normalizá-la\n","img_array = image.img_to_array(img) / 255.\n","\n","# Expandir as dimensões da imagem para que ela possa ser passada para o modelo\n","img_array = np.expand_dims(img_array, axis=0)\n","\n","# Fazer a previsão\n","predictions = model.predict(img_array)\n","\n","# Obter a classe prevista\n","predicted_class = classes[np.argmax(predictions)]\n","\n","print(f\"A imagem foi classificada como '{predicted_class}'.\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOZ+jZ+Bpa612JYW4HS8B5x","gpuType":"T4","mount_file_id":"1NG4HWUWWQZJ6-prBQ52hVvj39zSyXTzT","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
